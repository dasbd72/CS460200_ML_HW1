{"cells":[{"cell_type":"markdown","metadata":{"id":"X_Te27fi-0pP"},"source":["# **HW1: Regression**\n","\n","In _assignment 1_, you need to finish:\n","\n","1.  Basic Part: Implement the regression model to predict the number of dengue cases\n","\n","> - Step 1: Split Data\n","> - Step 2: Preprocess Data\n","> - Step 3: Implement Regression\n","> - Step 4: Make Prediction\n","> - Step 5: Train Model and Generate Result\n","\n","2.  Advanced Part: Implementing a regression model to predict the number of dengue cases in a different way than the basic part\n"]},{"cell_type":"markdown","metadata":{"id":"_wDdnos-4uUv"},"source":["# 1. Basic Part (60%)\n","\n","In the first part, you need to implement the regression to predict the number of dengue cases\n","\n","Please save the prediction result in a csv file **hw1_basic.csv**\n"]},{"cell_type":"markdown","metadata":{"id":"RzCR7vk9BFkf"},"source":["## Import Packages\n","\n","> Note: You **cannot** import any other package in the basic part\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HL5XjqFf4wSj"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import csv\n","import math\n","import random\n"]},{"cell_type":"markdown","metadata":{"id":"jnWjrzi0dMPz"},"source":["## Global attributes\n","\n","Define the global attributes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EWLDPOlHBbcK"},"outputs":[],"source":["# Input file named as 'hw1_basic_input.csv'\n","input_dataroot = 'hw1_basic_input.csv'\n","# Output file will be named as 'hw1_basic.csv'\n","output_dataroot = 'hw1_basic.csv'\n","\n","# Initial datalist, saved as numpy array\n","input_datalist = []\n","# Your prediction, should be 10 * 4 matrix and saved as numpy array\n","output_datalist = []\n","# The format of each row should be ['epiweek', 'CityA', 'CityB', 'CityC']\n","\n","train_dataset = []\n","validation_dataset = []\n","toPredict_dataset = []\n","models = []\n"]},{"cell_type":"markdown","metadata":{"id":"PsFC-cvqIcYK"},"source":["You can add your own global attributes here\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["MatrixInversion = \"MatrixInversion\"\n","GradientDescent = \"GradientDescent\"\n","\n","# data\n","input_ratio = 1\n","output_weeks = 10\n","train_all = False\n","validation_ratio = 0.2\n","preprocess_data = True\n","preprocess_all_columns = True\n","drop_unwanted = False\n","\n","# auto regression\n","previous_weeks = 5\n","order_per_weeks = 4\n","# fitting_method = MatrixInversion\n","fitting_method = GradientDescent\n","\n","# gradient descent\n","learning_rate = 5e-2\n","iterations = 50000\n","\n","# pd.set_option('display.max_rows', df.shape[0]+1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OUbS2BEgcut6"},"outputs":[],"source":["def calc_mape(pred_Y, Y):\n","    mape = np.mean(np.absolute((Y - pred_Y) / Y), dtype=np.float32) * 100\n","    return mape\n","\n","\n","def get_xy(input_data, x_idx):\n","    ret_x = []\n","    for i in range(3):\n","        X = input_data[previous_weeks:, [i+ii for ii in x_idx]]\n","        if (previous_weeks):\n","            for d in range(previous_weeks):\n","                for o in range(order_per_weeks):\n","                    X = np.hstack((X, np.float_power(input_data[d:-previous_weeks+d, [i+4]], o+1)))\n","        ret_x.append(X)\n","    ret_y = [input_data[previous_weeks:, [i+4]] for i in range(3)]\n","    return (ret_x, ret_y)\n","\n","\n","class auto_regression_model:\n","    def __init__(self, method=MatrixInversion):\n","        self.method = method\n","        self.w = None\n","\n","    def fit(self, X, Y):\n","        m, n = X.shape\n","        self.M = X.mean(axis=0)\n","        self.S = X.max(axis=0) - X.min(axis=0)\n","        X = self.normalize(X)\n","        X = np.hstack((np.ones((m, 1)), X))\n","\n","        if (self.method == MatrixInversion):\n","            ''' w = ((phi^T)*(phi))^-1 * phi^T * y '''\n","            self.w = np.linalg.lstsq(X, Y, rcond=None)[0]\n","\n","        elif (self.method == GradientDescent):\n","            pred_Y = np.copy(Y)\n","            # for it in range(10):\n","            for it in range(iterations):\n","                if (it == 0):\n","                    self.w = np.random.rand(n+1,1)\n","                pred_Y = X.dot(self.w)\n","                diff_y = Y - pred_Y\n","                g = 2 * np.mean(diff_y * X, axis=0).reshape(-1, 1)\n","                self.w = self.w + learning_rate * g\n","\n","    def predict(self, X: np.ndarray):\n","        m, n = X.shape\n","        X = X.copy()\n","        pred_Y = np.ndarray((m, 1))\n","        for r in range(m):\n","            row_X = X[[r]]\n","            yy = self.get_y(row_X)[0, 0]\n","            pred_Y[[r], 0] = yy\n","            for d in range(previous_weeks, 0, -1):\n","                if (r + d >= m):\n","                    break\n","                # X[r+d, -d] = yy\n","                for o in range(order_per_weeks):\n","                    X[r+d, -d*order_per_weeks+o] = yy\n","            # print(X.astype(np.int32))\n","        return pred_Y\n","\n","    def get_y(self, X: np.ndarray):\n","        X = self.normalize(X)\n","        X = np.hstack((np.ones((X.shape[0], 1)), X))\n","        return X.dot(self.w)\n","\n","    def normalize(self, X: np.ndarray):\n","        return (X - self.M) / self.S\n","\n","    def get_model(self):\n","        return self.w\n","\n","\n","models.append(auto_regression_model(method=fitting_method))\n","\n","models.append(auto_regression_model(method=fitting_method))\n","\n","models.append(auto_regression_model(method=fitting_method))\n"]},{"cell_type":"markdown","metadata":{"id":"rUoRFoQjBW5S"},"source":["## Load the Input File\n","\n","First, load the basic input file **hw1_basic_input.csv**\n","\n","Input data would be stored in _input_datalist_\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dekR1KnqBtI6"},"outputs":[],"source":["# Read input csv to datalist\n","with open(input_dataroot, newline='') as csvfile:\n","    input_datalist = np.array(list(csv.reader(csvfile)))\n"]},{"cell_type":"markdown","metadata":{"id":"6kYPuikLCFx4"},"source":["## Implement the Regression Model\n","\n","> Note: It is recommended to use the functions we defined, you can also define your own functions\n"]},{"cell_type":"markdown","metadata":{},"source":["### Step 0: Preprocess\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def PreprocessDatalist(datalist, x_idx=[1, 2, 3]):\n","    df = pd.DataFrame(datalist)\n","    df = df.iloc[1:]\n","    df = df.replace('', np.nan).astype(np.float32)\n","\n","    toPredict = df.iloc[-output_weeks:].to_numpy()\n","    df = df.iloc[:-output_weeks]\n","\n","    if preprocess_data:\n","        Q1 = df.quantile(0.25)\n","        Q3 = df.quantile(0.75)\n","        IQR = Q3 - Q1\n","        ldf = df < (Q1 - 1.5 * IQR)\n","        rdf = df > (Q3 + 1.5 * IQR)\n","        if (preprocess_all_columns):\n","            df[(ldf | rdf)] = np.nan\n","\n","        else:\n","            df[(ldf | rdf).loc[:, x_idx]] = np.nan\n","\n","    if(drop_unwanted):\n","        df = df.dropna()\n","    else:\n","        df = df.interpolate()\n","        df = df.fillna(method=\"ffill\")\n","        df = df.fillna(method=\"bfill\")\n","\n","    datalist = df.to_numpy()\n","    if (previous_weeks > 0):\n","        toPredict = np.vstack((datalist[-previous_weeks:], toPredict))\n","\n","    # with open(\"datalist.csv\", 'w', newline='', encoding=\"utf-8\") as csvfile:\n","    #     writer = csv.writer(csvfile)\n","    #     for row in datalist:\n","    #         writer.writerow(row)\n","\n","    return (datalist, toPredict)"]},{"cell_type":"markdown","metadata":{"id":"jWwdx06JNEYs"},"source":["### Step 1: Split Data\n","\n","Split data in _input_datalist_ into training dataset and validation dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"USDciENcB-5F"},"outputs":[],"source":["def SplitData(datalist):\n","    print(\"Spliting Data...\")\n","\n","    # print(pd.DataFrame(datalist).describe())\n","    input_weeks = int(datalist.shape[0] * input_ratio)\n","    datalist = datalist[-input_weeks:]\n","    # print(pd.DataFrame(datalist).describe())\n","    print(f\"data weeks: {input_weeks}\")\n","\n","    train_weeks = int(datalist.shape[0] * (1 - validation_ratio))\n","    train = []\n","    if(train_all):\n","        train = datalist\n","    else:\n","        train = datalist[:train_weeks]\n","    validation = datalist[train_weeks-previous_weeks:]\n","\n","    return (train, validation)\n"]},{"cell_type":"markdown","metadata":{"id":"u-3Qln4aNgVy"},"source":["### Step 2: Preprocess Data\n","\n","Handle the unreasonable data\n","\n","> Hint: Outlier and missing data can be handled by removing the data or adding the values with the help of statistics\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XXvW1n_5NkQ5"},"outputs":[],"source":["def PreprocessData():\n","    return\n"]},{"cell_type":"markdown","metadata":{"id":"yDLpJmQUN3V6"},"source":["### Step 3: Implement Regression\n","\n","> Hint: You can use Matrix Inversion, or Gradient Descent to finish this part\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tx9n1_23N8C0"},"outputs":[],"source":["def Regression(models, train, validation, x_idx:list=[1]):\n","    train_x, train_y = get_xy(train, x_idx)\n","    validation_x, validation_y = get_xy(validation, x_idx)\n","    \n","    # train_x = []\n","    # for i in range(3):\n","    #     X = train[previous_weeks:, [i+ii for ii in x_idx]]\n","    #     if (previous_weeks):\n","    #         for d in range(previous_weeks):\n","    #             for o in range(order_per_weeks):\n","    #                 X = np.hstack((X, np.float_power(train[d:-previous_weeks+d, [i+4]], o+1)))\n","    #     train_x.append(X)\n","    # train_y = [train[previous_weeks:, [i+4]] for i in range(3)]\n","    # validation_x = []\n","    # for i in range(3):\n","    #     X = validation[previous_weeks:, [i+ii for ii in x_idx]]\n","    #     if (previous_weeks):\n","    #         for d in range(previous_weeks):\n","    #             for o in range(order_per_weeks):\n","    #                 X = np.hstack(\n","    #                     (X, np.float_power(validation[d:-previous_weeks+d, [i+4]], o+1)))\n","    #     validation_x.append(X)\n","    # validation_y = [validation[previous_weeks:, [i+4]] for i in range(3)]\n","\n","    mape_sum = 0\n","    for i in range(len(models)):\n","        X, Y = train_x[i], train_y[i]\n","        models[i].fit(X, Y)\n","\n","        if (validation_ratio != 0):\n","            X, Y = validation_x[i], validation_y[i]\n","            pred_y = models[i].predict(X)\n","            mape = calc_mape(pred_y, Y)\n","            mape_sum += mape\n","            print(f\"MAPE {chr(i+65)}: {mape}%\")\n","\n","    for i in range(len(models)):\n","        plt.subplot(231)\n","        plt.title(\"train: y truth\")\n","        plt.plot(train_y[i])\n","        plt.subplot(232)\n","        plt.title(\"train: x dot w\")\n","        plt.plot(models[i].get_y(train_x[i]))\n","        plt.subplot(233)\n","        plt.title(\"train: predict(x)\")\n","        plt.plot(models[i].predict(train_x[i]))\n","        plt.subplot(234)\n","        plt.title(\"validation: y truth\")\n","        plt.plot(validation_y[i])\n","        plt.subplot(235)\n","        plt.title(\"validation: x dot w\")\n","        plt.plot(models[i].get_y(validation_x[i]))\n","        plt.subplot(236)\n","        plt.title(\"validation: predict(x)\")\n","        plt.plot(models[i].predict(validation_x[i]))\n","        plt.show()\n","\n","    if (validation_ratio != 0):\n","        print(f\"Average MAPE: {mape_sum / 3}%\")\n","    return\n"]},{"cell_type":"markdown","metadata":{"id":"2NxRNFwyN8xd"},"source":["### Step 4: Make Prediction\n","\n","Make prediction of testing dataset and store the value in _output_datalist_\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EKlDIC2-N_lk"},"outputs":[],"source":["def MakePrediction(models, toPredict, x_idx:list=[1]):\n","    def f(result):\n","        result[result < 0] = 0\n","        result = np.round(result).astype(np.int64)\n","        return result\n","\n","    toPredict_x, toPredict_y = get_xy(toPredict, x_idx)\n","\n","    # toPredict_x = []\n","    # for i in range(3):\n","    #     X = toPredict[previous_weeks:, [i+ii for ii in x_idx]]\n","    #     if (previous_weeks):\n","    #         for d in range(previous_weeks):\n","    #             for o in range(order_per_weeks):\n","    #                 X = np.hstack((X, np.float_power(toPredict[d:-previous_weeks+d, [i+4]], o+1)))\n","    #     toPredict_x.append(X)\n","    # toPredict_y = [toPredict[previous_weeks:, [i+4]] for i in range(3)]\n","\n","    output_datalist = toPredict[-output_weeks:, [0]].astype(np.int64)\n","\n","    for i in range(len(models)):\n","        result = f(models[i].predict(toPredict_x[i]))\n","        output_datalist = np.hstack((output_datalist, result))\n","\n","    return output_datalist\n"]},{"cell_type":"markdown","metadata":{"id":"cCd0Z6izOCwq"},"source":["### Step 5: Train Model and Generate Result\n","\n","> Notice: **Remember to output the coefficients of the model here**, otherwise 5 points would be deducted\n","\n","- If your regression model is _3x^2 + 2x^1 + 1_, your output would be:\n","\n","```\n","3 2 1\n","```\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iCL92EPKOFIn"},"outputs":[],"source":["input_datalist, toPredict_dataset = PreprocessDatalist(input_datalist)\n","# print(input_datalist.astype(np.int64))\n","train_dataset, validation_dataset = SplitData(input_datalist)\n","PreprocessData()\n","Regression(models, train_dataset, validation_dataset)\n","output_datalist = MakePrediction(models, toPredict_dataset)\n","print(\"validation ratio:\", validation_ratio)\n","print(\"previous weeks:\", previous_weeks)\n","print(\"orders per weeks:\", order_per_weeks)\n","\n","for i in range(3):\n","    print(f\"model {chr(i+65)}:\", models[i].get_model().reshape(-1))\n","    # print(models[i].M)\n","    # print(models[i].S)\n"]},{"cell_type":"markdown","metadata":{"id":"J8Jhd8wAOk3D"},"source":["## Write the Output File\n","\n","Write the prediction to output csv\n","\n","> Format: 'epiweek', 'CityA', 'CityB', 'CityC'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tYQVYLlKOtDB"},"outputs":[],"source":["with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n","    writer = csv.writer(csvfile)\n","    for row in output_datalist:\n","        writer.writerow(row)\n"]},{"cell_type":"markdown","metadata":{"id":"rx4408qg4xMQ"},"source":["# 2. Advanced Part (35%)\n","\n","In the second part, you need to implement the regression in a different way than the basic part to help your predictions for the number of dengue cases\n","\n","We provide you with two files **hw1_advanced_input1.csv** and **hw1_advanced_input2.csv** that can help you in this part\n","\n","Please save the prediction result in a csv file **hw1_advanced.csv**\n"]},{"cell_type":"markdown","metadata":{},"source":["## Attributes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DaZCe19m41g1"},"outputs":[],"source":["advanced_input_dataroot = 'hw1_basic_input.csv'\n","advanced_input1_dataroot = 'hw1_advanced_input1.csv'\n","advanced_input2_dataroot = 'hw1_advanced_input2.csv'\n","advanced_output_dataroot = 'hw1_advanced.csv'\n","\n","advanced_input_datalist = []\n","advanced_input1_datalist = []\n","advanced_input2_datalist = []\n","advanced_output_datalist = []\n","\n","train_dataset = []\n","validation_dataset = []\n","toPredict_dataset = []\n","\n","models = [auto_regression_model(method=fitting_method) for _ in range(3)]\n"]},{"cell_type":"markdown","metadata":{},"source":["## Load Files\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Read input csv to datalist\n","with open(advanced_input_dataroot, newline='') as csvfile:\n","    advanced_input_datalist = np.array(list(csv.reader(csvfile)))\n","\n","with open(advanced_input1_dataroot, newline='') as csvfile:\n","    advanced_input1_datalist = np.array(list(csv.reader(csvfile)))\n","\n","with open(advanced_input2_dataroot, newline='') as csvfile:\n","    advanced_input2_datalist = np.array(list(csv.reader(csvfile)))\n"]},{"cell_type":"markdown","metadata":{},"source":["### Implementation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["advanced_input_datalist = np.hstack(\n","    (advanced_input_datalist, advanced_input1_datalist[:, 1:]))\n","advanced_input_datalist, toPredict_dataset = PreprocessDatalist(\n","    advanced_input_datalist, x_idx=[1,2,3,7,8,9])\n","train_dataset, validation_dataset = SplitData(advanced_input_datalist)\n","Regression(models, train_dataset, validation_dataset, x_idx=[1,7])\n","advanced_output_datalist = MakePrediction(models, toPredict_dataset, x_idx=[1,7])\n","\n","print(\"model A:\", models[0].get_model().reshape(-1))\n","print(\"model B:\", models[1].get_model().reshape(-1))\n","print(\"model C:\", models[2].get_model().reshape(-1))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import torch\n","# import torch.nn as nn\n","# from torchmetrics.functional import mean_absolute_percentage_error\n","\n","# train_x = []\n","# for i in range(3):\n","#     X = train_dataset[previous_weeks:, [i+1, i+7]]\n","#     if (previous_weeks):\n","#         for d in range(previous_weeks):\n","#             X = np.hstack((X, train_dataset[d:-previous_weeks+d, [i+4]]))\n","#     train_x.append(torch.from_numpy(X))\n","# train_y = [torch.from_numpy(train_dataset[previous_weeks:, [i+4]])\n","#            for i in range(3)]\n","# validation_x = []\n","# for i in range(3):\n","#     X = validation_dataset[previous_weeks:, [i+1, i+7]]\n","#     if (previous_weeks):\n","#         for d in range(previous_weeks):\n","#             X = np.hstack((X, validation_dataset[d:-previous_weeks+d, [i+4]]))\n","#     validation_x.append(torch.from_numpy(X))\n","# validation_y = [torch.from_numpy(\n","#     validation_dataset[previous_weeks:, [i+4]]) for i in range(3)]\n","\n","# n_samples, n_features = train_x[0].shape\n","\n","\n","# class LinearRegression(nn.Module):\n","\n","#     def __init__(self, input_dim, output_dim):\n","#         super(LinearRegression, self).__init__()\n","\n","#         # define layers\n","#         self.linear = nn.Linear(input_dim, output_dim)\n","\n","#     def forward(self, x):\n","\n","#         return self.linear(x)\n","\n","\n","# models = [LinearRegression(n_features, 1) for _ in range(3)]\n","\n","# learning_rate = 0.00001\n","# criterion = nn.MSELoss()\n","# epochs = 10000\n","# mape_sum = 0\n","# for i in range(len(models)):\n","#     print(f\"Model {chr(i+65)} training.\")\n","#     optimizer = torch.optim.SGD(models[i].parameters(), lr=learning_rate)\n","#     for epoch in range(epochs):\n","#         # forward pass and loss\n","#         pred_y = models[i](train_x[i])\n","#         # print(pred_y)\n","#         loss = criterion(pred_y, train_y[i])\n","\n","#         # backward pass\n","#         loss.backward()\n","\n","#         # update\n","#         optimizer.step()\n","\n","#         # init optimizer\n","#         optimizer.zero_grad()\n","\n","#         if (epoch + 1) % 10 == 0:\n","#             print(f'epoch: {epoch+1}, loss = {loss.item(): .4f}', end='\\r')\n","#     print()\n","\n","#     if(validation_ratio):\n","#         pred_y = [models[i](x) for x in validation_x[i]]\n","#         pred_y = torch.tensor(pred_y).reshape(-1,1)\n","#         mape = mean_absolute_percentage_error(pred_y, validation_y[i]) * 100\n","#         mape_sum += mape\n","#         print(f'MAPE = {mape}%')\n","# print(f'Average MAPE = {mape_sum / 3}%')\n"]},{"cell_type":"markdown","metadata":{},"source":["## Write Ouptut File\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open(advanced_output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n","    writer = csv.writer(csvfile)\n","    for row in advanced_output_datalist:\n","        writer.writerow(row)\n"]},{"cell_type":"markdown","metadata":{"id":"EtgCJU7FPeJL"},"source":["# Report _(5%)_\n","\n","Report should be submitted as a pdf file **hw1_report.pdf**\n","\n","- Briefly describe the difficulty you encountered\n","- Summarize your work and your reflections\n","- No more than one page\n"]},{"cell_type":"markdown","metadata":{"id":"hlEE53_MPf4W"},"source":["# Save the Code File\n","\n","Please save your code and submit it as an ipynb file! (**hw1.ipynb**)\n"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.9.7 ('venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"118e693a2673d7edd73bc7d659798e192144410f931e259501d1be14d636c605"}}},"nbformat":4,"nbformat_minor":0}
